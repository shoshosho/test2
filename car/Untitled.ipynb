{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import time\n",
    "import dask.dataframe as dskdf\n",
    "import dask\n",
    "gl = globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class test:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    #地域系は全部で４つのデータをマージする\n",
    "    #車種系は全部で●つのデーたをマージする\n",
    "    #車種の元ネタが成約データなので、最終的に車種データに地域データを市区町村名で紐付ける\n",
    "\n",
    "    #地域(1)\n",
    "    #市区町村別国勢調査\n",
    "    def make_kokusei(self):\n",
    "        kokusei = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/kokuseichosa_2015_for_merge.csv\")\n",
    "        #全てを英字変換する必要あり\n",
    "        kokusei.columns=[\"pref_code\", \"pref_city_code\", \"capital_city_flg\", \"city_categories\", \"chiho\", \"city_name\",\n",
    "                         \"population\", \"h22_kumikae_population\", \"population_changed_from_h22_to_h27\", \"rate_population_changed_from_h22_to_h27\",\n",
    "                         \"gross_area\", \"population_density\", \"ave_age_from_h22_to_h27\", \"med_age_from_h22_to_h27\", \"population\",\n",
    "                         \"population_under_15old\", \"population_from_15_to_64_old\", \"population_over_65old\", \"rate_population_under_15_year_old\",\n",
    "                         \"rate_population_from_15_to_64_old\", \"rate_population_over_65old\", \"population_male\",\"population_male_under_15old\",\n",
    "                         \"population_male_from_15_to_64_old\", \"population_male_over_65old\", \"rate_population_male_under_15old\",\n",
    "                         \"rate_population_male_from_15_to_64_old\", \"rate_population_male_over_65old\", \"population_female\",\n",
    "                         \"population_female_under_15old\", \"population_female_from_15_to_64_old\", \"population_female_over_65old\",\n",
    "                         \"rate_population_female_under_15old\", \"rate_population_female_from_15_to_64_old\", \"rate_population_female_over_65old\",\n",
    "                         \"rate_population_male_to female\", \"population_jap\", \"population_no_jap\", \"num_of_family\", \"num_of_normal_family\",\n",
    "                         \"num_of_family_in_facilities\", \"h22_kumikae_family\", \"num_of_normal_family\", \"num_of_nuclear_family\",\n",
    "                         \"num_of_family_no_children\", \"num_of_family_with_children\", \"num_of_father_and_children\", \"num_of_mother_and_children\",\n",
    "                         \"num_of_singles\", \"num_of_over_65old_singles\", \"num_of_old_married_couples_no_children\", \"num_of_3generation_family\",]\n",
    "        return kokusei\n",
    "\n",
    "    #chiho(都道府県名)で国勢調査と保有台数をマージ\n",
    "    def left_merge_on_chiho(self,left,right,out):\n",
    "        out = pd.merge(left,right,on=\"chiho\",how=\"left\")\n",
    "        #一番下に謎の欠損行が存在するので削除する\n",
    "        out = out.dropna(subset=['pref_code'])\n",
    "        return out\n",
    "\n",
    "    #地域(2)\n",
    "    #都道府県別保有台数\n",
    "    def make_hoyu(self):\n",
    "        hoyu = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/2015_hoyu_daisu.csv\",encoding=\"utf-8\")\n",
    "        hoyu.columns = [\"chiho\", \"num_of_cars_all\", \"num_of_cars_kei\", \"num_of_cars_normal\", \"num_of_familiy\", \"cars_per_person\",\n",
    "                        \"normal_cars_per_person\", \"kei_cars_per_person\", \"kei_rate\", \"normal_rate\", \"kei_share_in_JP\", \"normal_share_in_JP\",\n",
    "                        \"guess_2nd_hand_kei_car_sales_per_year\", \"guess_2nd_hand_normal_car_sales_per_year\", \"guess_2nd_hand_car_all_sales_per_year\"]\n",
    "        koku_hoyu = left_merge_on_chiho(kokusei, hoyu, \"koku_hoyu\")\n",
    "        return koku_hoyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tes = test()\n",
    "tes.make_kokusei()\n",
    "tes.make_hoyu()\n",
    "\n",
    "tes.kokusei.head()\n",
    "tes.koku_hoyu.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/01017387/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ku = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_1.csv\",delimiter=\"\\t\",encoding=\"cp932\")\n",
    "ru = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_2.csv\",delimiter=\"\\t\",encoding=\"cp932\")\n",
    "ma = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_3.csv\",delimiter=\"\\t\",encoding=\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kuru = pd.concat([ku,ru],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1378603, 30)\n",
      "(1378534, 30)\n",
      "(2757137, 60)\n"
     ]
    }
   ],
   "source": [
    "print(ku.shape)\n",
    "print(ru.shape)\n",
    "print(kuru.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kuruma = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/tes.csv\")\n",
    "ku = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_1.csv\",\n",
    "                 delimiter=\"\\t\", dtype=\"object\", encoding=\"cp932\",)\n",
    "colname = ku.columns\n",
    "ru = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_2.csv\",\n",
    "                 delimiter=\"\\t\", dtype=\"object\", encoding=\"cp932\",names=colname)\n",
    "ma = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/物件*問い合わせ/toiawase_3.csv\",\n",
    "                 delimiter=\"\\t\", dtype=\"object\", encoding=\"cp932\",names=colname)\n",
    "kuru = pd.concat([ku,ru],axis=0)\n",
    "kuruma = pd.concat([kuru,ma],axis=0)\n",
    "\n",
    "kuruma[\"b.shikuchoson_jusho_kj\"] = kuruma[\"b.shikuchoson_jusho_kj\"].str.replace('ヶ', 'ケ')\n",
    "kuruma[\"b.todofuken_jusho_kj\"] = kuruma[\"b.todofuken_jusho_kj\"].map(lambda x: str(x).strip())\n",
    "#県単位、市区町村単位での地方別集計（問い合わせ）\n",
    "#もともとの市区町村名に入ってるレベル感が違う(市区町村で終わるものもあれば、町大字まで入っているものもある)\n",
    "#市区町村マスタと一致する部分のみ残す\n",
    "\n",
    "#都道府県欠損を削除\n",
    "cu = kuruma.dropna(subset=[\"b.todofuken_jusho_kj\"])\n",
    "#都道府県名に異常値が入っているものを除く\n",
    "# '〓'が入っていたらアウト\n",
    "cus = cu.ix[cu['b.shikuchoson_jusho_kj'] != \"〓\"]\n",
    "cus = cus.ix[cus['b.shikuchoson_jusho_kj'] != \"null\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/加工済み/市区町村マスタ.csv\",names=[\"pref\",\"city\"])\n",
    "\n",
    "#h市区町村表記揺れを消したい\n",
    "dl[\"city\"] = dl[\"city\"].str.replace('ヶ', 'ケ')\n",
    "pre = dl[\"pref\"].unique() #array\n",
    "#県内市区町村数のカウント用\n",
    "dl[\"count\"] =1\n",
    "num = dl.groupby(\"pref\").sum()\n",
    "dc = num.to_dict()\n",
    "dic = dc[\"count\"]\n",
    "\n",
    "biglis = []\n",
    "c=0\n",
    "#都道府県別市区町村の格納\n",
    "for i in pre:\n",
    "    tmplis = []\n",
    "    for k in range(int(dic[i])):\n",
    "#             exec(\"tmplis.append(dl['city'][\"+str(c)+\"])\")\n",
    "        tmplis.append(dl['city'][c])\n",
    "        c +=1\n",
    "    #元データの入り方が札幌市→札幌市〇〇区、といった順で入っているので、上から部分一致で合致を探す際の障害になる\n",
    "    #ゆえに最初の要素を最後に持ってくる処理が必要\n",
    "    push_to_last = tmplis.pop(0)\n",
    "    tmplis.append(push_to_last)\n",
    "    biglis.append(tmplis)\n",
    "\n",
    "#辞書の作成\n",
    "#県名をキーとして、市区町村名のリストをバリューとする\n",
    "dicts = {key: value for (key, value) in zip(pre,biglis)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#dfの各要素について、辞書のどこに一致するかを見て、ループで部分一致を探す\n",
    "#部分一致したものをtoshiで保持する\n",
    "# ken = kuruma[\"b.todofuken_jusho_kj\"].values\n",
    "# ken = kuruma[\"b.todofuken_jusho_kj\"].map(lambda x: str(x).strip()).values\n",
    "# org_toshi = kuruma[\"b.shikuchoson_jusho_kj\"].values\n",
    "ken = cus[\"b.todofuken_jusho_kj\"].map(lambda x: str(x).strip()).values\n",
    "org_toshi = cus[\"b.shikuchoson_jusho_kj\"].values\n",
    "toshi = [] #整形した市区町村名\n",
    "counter =[] #部分一致するものがあるかどうかのフラグ\n",
    "cnt =0\n",
    "for k,i in zip(ken,org_toshi):\n",
    "#     print(dicts[k])\n",
    "#     cnt +=1\n",
    "#     if cnt>26304:\n",
    "#         print(k)\n",
    "#         print(dicts[k])\n",
    "    count=0\n",
    "    for l in dicts[k]:\n",
    "        if l in i:\n",
    "            toshi.append(l)\n",
    "            counter.append(1)\n",
    "            break\n",
    "        count+=1\n",
    "        if count >=(len(dicts[k])):\n",
    "            toshi.append(\"\")\n",
    "            counter.append(0)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#概ねOKだけど、県名の後に直接郡の名前が来るケースに対応できていない\n",
    "# →修正面倒なので後回し\n",
    "#スクレイピングで持ってくる必要ある：　http://www.geocities.jp/je2kcr/current_allgun.htm\n",
    "#toshiが欠損のものはとりあえず除外検討\n",
    "\n",
    "#bbをkurumaにマージ\n",
    "cus[\"city_name\"] = toshi\n",
    "cus[\"count\"] = 1\n",
    "#toiawase_dateの型を日付型に変更する必要がある\n",
    "cus[\"toiawase_datetime\"] = pd.to_datetime(cus[\"b.toiawase_date\"].str[:10] + \" \" + cus[\"b.toiawase_date\"].str[10:])\n",
    "cus[\"toiawase_y\"] = cus[\"toiawase_datetime\"].dt.year.astype(str)\n",
    "cus[\"toiawase_m\"] = cus[\"toiawase_datetime\"].dt.month.astype(str)\n",
    "cus[\"toiawase_ym\"] = cus[\"toiawase_y\"] + cus[\"toiawase_m\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import time\n",
    "import dask.dataframe as dskdf\n",
    "import dask\n",
    "\n",
    "gl = globals()\n",
    "\n",
    "class tes:\n",
    "    # -*- coding: utf-8 -*-\n",
    "\n",
    "    def make_catalogue(self):\n",
    "        cat_list = [\"mc1_body_type.txt\", \"mc1_kanren_shashu.txt\", \"mc1_brand.txt\", \"mc1_kihon_iro.txt\",\n",
    "                    \"mc1_brand_country.txt\",\n",
    "                    \"mc1_kukuri_kanren_shashu.txt\", \"mc1_brand_iro.txt\", \"mc1_maker.txt\", \"mc1_brand_maker.txt\",\n",
    "                    \"mc1_mc_model.txt\",\n",
    "                    \"mc1_country.txt\", \"mc1_mc_model_gazo.txt\", \"mc1_fmc_model.txt\", \"mc1_net_category.txt\",\n",
    "                    \"mc1_fp_shashu_midashi_settei_work.txt\", \"mc1_shashu.txt\", \"mc1_grade.txt\", \"mc1_sobi.txt\",\n",
    "                    \"mc1_grade_iro.txt\",\n",
    "                    \"mc1_transmission_henkan.txt\", \"mc1_grade_sobi.txt\"]\n",
    "        index_name = [\"ボディ形状マスタ\", \"関連車種マスタ\", \"ブランドマスタ\", \"基本色マスタ\", \"ブランド国設定マスタ\", \"括り関連車種マスタ\",\n",
    "                      \"ブランド色マスタ\", \"メーカーマスタ\", \"ブランドメーカー設定マスタ\", \"MCモデルマスタ\", \"国マスタ\", \"MCモデル画像マスタ\",\n",
    "                      \"FMCモデルマスタ\", \"NETカテゴリマスタ\", \"FP車種見出し設定マスタ\", \"車種マスタ\", \"グレードマスタ\", \"装備マスタ\",\n",
    "                      \"グレード色設定マスタ\", \"トランスミッション変換マスタ\", \"グレード装備設定マスタ\", ]\n",
    "        df_columns = [[\"body_shape_cd\", \"body_shape_nm\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"kanren_shashu_cate\", \"kanren_shashu_cate_no\", \"kanren_kj\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"brand_nm\", \"brand_hyoji_order\", \"catalogue_keisai_fuka_cate\", \"seo_folder_nm\",\n",
    "                       \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"base_color_cd\", \"base_color_nm\", \"base_color_hyoji_jun\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"country_cd\", \"daihyo_country_flg\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"kanren_shashu_cate\", \"kanren_shashu_cate_no\", \"brand_cd\", \"shashu_cd\",\n",
    "                       \"kukuri_kanren_shashu_hyoji_jun\",\n",
    "                       \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"brand_color_cd\", \"brand_color_nm\", \"base_color_cd\", \"jitsu_brand_color_nm\",\n",
    "                       \"brand_color_hyoji_order\", \"base_color_cd1\", \"base_color_cd2\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"maker_cd\", \"maker_nm\", \"maker_hyoji_jun\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"maker_cd\", \"daihyo_maker_flg\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"mc_hanbai_start\", \"mc_hanbai_end\", \"mc_cate\", \"mc_kj\",\n",
    "                       \"mc_commment_title\", \"mc_comment\", \"catalogue_keisai_fuka_cate\", \"register_ymd\",\n",
    "                       \"last_modified_ymd\"],\n",
    "                      [\"country_cd\", \"country_nm\", \"area_cate\", \"country_hyoji_jun\", \"register_ymd\", \"daihyo_base_color\",\n",
    "                       \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"gazo_index_no\", \"mc_model_pic_hyoji_jun\",\n",
    "                       \"gazo_cate_cd\",\n",
    "                       \"caption\", \"catalogue_keisai_fuka_cate\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"fmc_hanbai_start\", \"fmc_hanbai_end\", \"fmc_kj\",\n",
    "                       \"catalogue_keisai_fuka_cate\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"net_cate_cd\", \"cate_nm\", \"net_cate_hyoji_jun\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\", \"fp_cate_cd\", \"fp_shashu_midashi_cd\",\n",
    "                       \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"shashu_nm\", \"wareki_seireki_cate\", \"shashu_hyoji_jun\",\n",
    "                       \"catalogue_keisai_fuka_cate\", \"search_key_1\", \"search_key_2\", \"search_key_3\", \"seo_folder_nm\",\n",
    "                       \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\", \"grade_kukuri_cd\", \"grade_nm\",\n",
    "                       \"grade_hyoji_jun\",\n",
    "                       \"body_shape_cd\", \"grade_hanbai_start_ym\", \"grade_hanbai_end_ym\", \"katashiki\", \"ruibetsu_kigo\",\n",
    "                       \"katashiki_shitei_no\", \"ruibetsu_cate_no\", \"price_with_tax\", \"price_without_tax\",\n",
    "                       \"nenpi_kijun_achieve_cate\", \"nenpi_kijun_nen\", \"low_emission_nintei_stars\",\n",
    "                       \"low_emission_nintei_nen\",\n",
    "                       \"reduce_tax_cate\", \"heiko_yunyusha_cate\", \"walfare_car_cate\", \"car_for_commercial_use\", \"kei_flg\",\n",
    "                       \"number_size\", \"special_edition_flg\", \"catalogue_keisai_fuka_cate\", \"keisai_commentary\",\n",
    "                       \"kudo_hoshiki_cate\", \"transmission_su\", \"transmission_cate\", \"transmission_ichi_cate\",\n",
    "                       \"transmission_cd\",\n",
    "                       \"handle_ichi_cate\", \"length\", \"width\", \"height\", \"inner_length\", \"inner_width\", \"inner_height\",\n",
    "                       \"wheel_base\", \"front_tred\", \"back_tred\", \"min_shako\", \"weight_of_car\", \"weight_of_car_all\",\n",
    "                       \"max_carriage\", \"max_carriage_persons\", \"min_kaiten_hankei\", \"10_15_mode_nenpiritsu\",\n",
    "                       \"stearing_gear_cate\", \"stearing_gear_nm\", \"front_suspension_cate\", \"front_suspension_nm\",\n",
    "                       \"back_suspension_cate\", \"back_suspension_nm\", \"front_break_cate\", \"front_break_nm\",\n",
    "                       \"back_break_cate\",\n",
    "                       \"back_break_nm\", \"front_tire_txt\", \"back_tire_txt\", \"engine_katashiki\", \"engine_valve_cate\",\n",
    "                       \"engine_silinder_cate\", \"engine_kito_su\", \"engine_kakyuki_cate\", \"engine_cate\", \"silinder_radius\",\n",
    "                       \"silinder_koutei\", \"total_haikiryo\", \"haikiryo1\", \"haikiryo2\", \"asshukuhi\", \"max_shuturyoku_kw\",\n",
    "                       \"max_shuturyoku_ps\", \"max_shuturyoku_rmp_max\", \"max_shuturyoku_rmp_min\", \"max_torque_mn\",\n",
    "                       \"max_torque_kgm\", \"max_torque_rpm_max\", \"max_torque_rpm_min\", \"fuel_sapply_device_cate\", \"fuel_cate\",\n",
    "                       \"fuel_tank_capacity\", \"door_su\", \"seat_columns\", \"net_cate_cd\", \"register_ymd\", \"last_modified_ymd\",\n",
    "                       \"jc08_mode_nenpi_rtsu\"],\n",
    "                      [\"equipment_cd\", \"equipment_nm\", \"equipment_bunrui_cate\", \"catalogue_keisai_cate\",\n",
    "                       \"equipment_hyoji_jun\",\n",
    "                       \"equipment_usage_cd\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\", \"brand_color_cd\", \"option_flg\",\n",
    "                       \"option_price\",\n",
    "                       \"grade_hyoji_jun\", \"register_ymd\", \"last_modified_ymd\"],\n",
    "                      [\"transmission_cd\", \"transmission_su\", \"transmission_cate\", \"transmission_ichi_cate\", \"register_ymd\",\n",
    "                       \"last_modified_ymd\"],\n",
    "                      [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\", \"equipment_cd\", \"equipment_nm\",\n",
    "                       \"equipment_jokyo_cd\", \"nm\", \"register_ymd\", \"last_modified_ymd\"]\n",
    "                      ]\n",
    "        # 読んだ後にとりあえず全部くっつけたい\n",
    "        co = 0\n",
    "        df_names = []\n",
    "        for ct in cat_list:\n",
    "            df_names.append(ct.rstrip(\".txt\")[4:])\n",
    "\n",
    "        start = time.time\n",
    "        self.dfs = []\n",
    "        cnt = 0\n",
    "        for cat, dn, dc in zip(cat_list, df_names, df_columns):\n",
    "            var = 'cat_' + str(dn)  # 変数名\n",
    "            tgt = '/Users/01017387/Desktop/しごと/data/car用/車カタログ/' + str(cat)\n",
    "\n",
    "            if cat in [\"mc1_grade_sobi.txt\", \"mc1_grade_iro.txt\", \"mc1_brand_iro.txt\"]:\n",
    "                gl[var] = pd.read_csv(tgt, encoding=\"cp932\", delimiter=\"\\t\", names=dc, nrows=10000)\n",
    "            # exec('cat_'+str(dn)+' = pd.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/車カタログ/'+str(cat)+'\",encoding=\"cp932\",delimiter=\"\\t\",names='+str(dc)+')')\n",
    "            # 型指定がうまくいかなくてエラーになるので、すべてobjectで読み込む\n",
    "            else:\n",
    "                gl[var] = dskdf.read_csv(tgt, encoding=\"cp932\", delimiter=\"\\t\", dtype=\"object\", names=dc).head(n=10000)\n",
    "            # exec('cat_'+str(dn)+' = dskdf.read_csv(\"/Users/01017387/Desktop/しごと/data/car用/車カタログ/'+str(cat)+'\",encoding=\"cp932\",delimiter=\"\\t\",low_memory=False,dtype=\"object\",names='+str(dc)+')')\n",
    "            cnt += 1\n",
    "            # 登録日、更新日は不要なので読み込み時点で落とす\n",
    "            #     exec('\"cat_\"+'+str(dn)+'[\"last_modified_tmd\"]')\n",
    "\n",
    "            # データ名もリストに格納しておく\n",
    "            self.dfs.append(\"self.cat_\" + str(dn))\n",
    "        # print('cat_'+str(dn))\n",
    "        #     print(cat)\n",
    "        #     co +=1\n",
    "        #     if co ==17:\n",
    "        #         break\n",
    "\n",
    "        # 少しでも軽くするために、不要な変数を削除しておく\n",
    "        for dd in self.dfs:\n",
    "            # print(dd)\n",
    "            gl[dd] = gl[dd].drop(\"register_ymd\", axis=1)\n",
    "            gl[dd] = gl[dd].drop(\"last_modified_ymd\", axis=1)\n",
    "            if dd == \"cat_grade\":\n",
    "                gl[dd] = gl[dd].drop(\"number_size\", axis=1)\n",
    "                gl[dd] = gl[dd].drop(\"catalogue_keisai_fuka_cate\", axis=1)\n",
    "            if dd == \"cat_mc_model\":\n",
    "                gl[dd] = gl[dd].drop(\"catalogue_keisai_fuka_cate\", axis=1)\n",
    "            if dd == \"cat_shashu\":\n",
    "                gl[dd] = gl[dd].drop(\"catalogue_keisai_fuka_cate\", axis=1)\n",
    "                gl[dd] = gl[dd].drop(\"search_key_1\", axis=1)\n",
    "                gl[dd] = gl[dd].drop(\"search_key_2\", axis=1)\n",
    "                gl[dd] = gl[dd].drop(\"search_key_3\", axis=1)\n",
    "                gl[dd] = gl[dd].drop(\"seo_folder_nm\", axis=1)\n",
    "            if dd == \"cat_sobi\":\n",
    "                gl[dd] = gl[dd].drop(\"equipment_hyoji_jun\", axis=1)\n",
    "\n",
    "        # 作成したデータは全て後ほど使うので、returnで返しておく\n",
    "        return self.dfs\n",
    "    # カタログ全体のマージ準備\n",
    "\n",
    "    def catalogue_merge_pre(self):\n",
    "        # 装備ごとに作られているテーブルが存在するので、装備をダミー変数化するためにpivotする必要がある\n",
    "        # ダミー化した変数の内容がわかるように、全てにsobi_の接頭辞をつけておく\n",
    "        self.cat_grade_sobi_pv = pd.pivot_table(self.cat_grade_sobi,\n",
    "                                                index=[\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\"],\n",
    "                                                columns=\"equipment_nm\", values=\"equipment_jokyo_cd\").reset_index()\n",
    "        col_equip = [\"sobi_\" + str(x) for x in self.cat_grade_sobi_pv.columns[5:, ]]\n",
    "        bs = ['brand_cd', 'shashu_cd', 'fmc_cd', 'mc_cd', 'grade_cd']\n",
    "        bs.extend(col_equip)\n",
    "        self.cat_grade_sobi_pv.columns = bs\n",
    "\n",
    "        # grade_iroは先にbrand_iroとマージして、基本色を獲得しておく\n",
    "        cat_grade_iro[\"count\"] = 1\n",
    "        cat_grade_brand_iro = pd.merge(cat_grade_iro, cat_brand_iro.ix[:, [\"brand_cd\", \"brand_color_cd\", \"base_color_cd\"]],\n",
    "                                       on=[\"brand_cd\", \"brand_color_cd\"])\n",
    "        self.sum_grade_brand_iro = pd.pivot_table(cat_grade_brand_iro,\n",
    "                                                  index=[\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\"],\n",
    "                                                  columns=\"base_color_cd\", values=\"count\").reset_index()\n",
    "\n",
    "        # ダミー化した変数の内容がわかるように、全てにbase_color_の接頭辞をつけておく\n",
    "        col_colors = [\"base_color_\" + str(x) for x in self.sum_grade_brand_iro.columns[5:, ]]\n",
    "        bs = ['brand_cd', 'shashu_cd', 'fmc_cd', 'mc_cd', 'grade_cd']\n",
    "        bs.extend(col_colors)\n",
    "        self.sum_grade_brand_iro.columns = bs\n",
    "\n",
    "        return [self.cat_grade_sobi_pv, self.sum_grade_brand_iro]\n",
    "\n",
    "\n",
    "    # カタログ全体のマージ\n",
    "    def catalogue_merge(self):\n",
    "        # 上記前処理が終わったら、ループで各種データをマージする\n",
    "        merge_key = [[\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\"], [\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\"],\n",
    "                     [\"brand_cd\", \"shashu_cd\", \"fmc_cd\"], [\"brand_cd\", \"shashu_cd\"], [\"brand_cd\", \"shashu_cd\"],\n",
    "                     [\"body_shape_cd\"], [\"transmission_cd\"], [\"brand_cd\"], [\"brand_cd\"], [\"brand_cd\"],\n",
    "                     [\"kanren_shashu_cate\"]\n",
    "                     ]\n",
    "\n",
    "        merge_data = [\"self.cat_grade\", \"self.cat_mc_model\", \"self.cat_fmc_model\", \"self.cat_shashu\", \"self.cat_kukuri_kanren_shashu\",\n",
    "                      \"self.cat_body_type\",\n",
    "                      \"self.cat_transmission_henkan\", \"self.cat_brand_country\", \"self.cat_brand_maker\", \"self.cat_brand\", \"self.cat_kanren_shashu\"\n",
    "                      ]\n",
    "\n",
    "        loops = np.array(list(range(11))) + 2\n",
    "\n",
    "        pandas_list = [\"mc1_body_type.txt\", \"mc1_kanren_shashu.txt\"]\n",
    "\n",
    "        # dask_ver\n",
    "        # a1 = cat_grade_sobi.merge(cat_grade_iro,on=[\"brand_cd\",\"shashu_cd\",\"fmc_cd\",\"mc_cd\",\"grade_cd\"])\n",
    "        # pandas_ver\n",
    "        moto = pd.merge(self.cat_grade_sobi_pv, self.sum_grade_brand_iro,\n",
    "                        on=[\"brand_cd\", \"shashu_cd\", \"fmc_cd\", \"mc_cd\", \"grade_cd\"])\n",
    "        # a1をdask化\n",
    "        a1 = dskdf.from_pandas(moto, npartitions=1)\n",
    "\n",
    "        cnt = 0\n",
    "        # dask_ver\n",
    "        print(loops)\n",
    "        for mk, md, lp in zip(merge_key, merge_data, loops):\n",
    "            #     a2 = a1.merge(cat_grade,on=[\"brand_cd\",\"shashu_cd\",\"fmc_cd\",\"mc_cd\",\"grade_cd\"])\n",
    "            var = 'a' + str(lp)\n",
    "            var_1 = 'a' + str(lp - 1)\n",
    "\n",
    "            print(var)\n",
    "            print(var_1)\n",
    "            gl[var] = gl[var_1].merge(gl[md], on=mk)\n",
    "\n",
    "        self.a12 = a12.copy()\n",
    "        # ファイルが死ぬほど大きいので退避させておく\n",
    "        self.a12.to_csv(\"/Users/01017387/Desktop/しごと/data/car用/車カタログ/test/car_catalogue_ss.csv\")\n",
    "        return self.a12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "te = tes()\n",
    "te.make_catalogue()\n",
    "te.catalogue_merge_pre()\n",
    "te.catalogue_merge()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
